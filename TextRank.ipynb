{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "TensorFlow 2.4 on Python 3.8 (CUDA 11.1)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "TextRank.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChungbinKim/-/blob/master/TextRank.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOU8hPtyTRPJ",
        "outputId": "9c5d00fc-f7db-4e1d-e02f-feb3ffdc4342"
      },
      "source": [
        "!pip install konlpy\n",
        "import glob\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sys\n",
        "import os\n",
        "import re\n",
        "import datetime \n",
        "import networkx\n",
        "import json\n",
        "from konlpy.tag import Komoran"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting konlpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4MB 63.9MB/s \n",
            "\u001b[?25hCollecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Collecting beautifulsoup4==4.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 8.4MB/s \n",
            "\u001b[?25hCollecting JPype1>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/a5/9781e2ef4ca92d09912c4794642c1653aea7607f473e156cf4d423a881a1/JPype1-1.2.1-cp37-cp37m-manylinux2010_x86_64.whl (457kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 41.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
            "Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.12.5)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Installing collected packages: colorama, beautifulsoup4, JPype1, konlpy\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed JPype1-1.2.1 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9sZCP1c_iZy"
      },
      "source": [
        ""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_yV71TWTRPM"
      },
      "source": [
        "tagger = Komoran()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rO2fEgTTRPO"
      },
      "source": [
        "### 1. 전처리용 클래스 정의"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpBNZBKSTRPP"
      },
      "source": [
        "#### 1. A.  원문 텍스트 클린징 + 모델에 문장 할당용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMYn31t-TRPP"
      },
      "source": [
        "class RawSentence:\n",
        "    def __init__(self, textIter):\n",
        "        if type(textIter) == str: self.textIter = textIter.split('\\n')\n",
        "        else: self.textIter = textIter\n",
        "        self.rgxSplitter = re.compile('([.!?:](?:[\"\\']|(?![0-9])))')\n",
        " \n",
        "    def __iter__(self):\n",
        "        for line in self.textIter:\n",
        "            ch = self.rgxSplitter.split(line)\n",
        "            for s in map(lambda a, b: a + b, ch[::2], ch[1::2]):\n",
        "                if not s: continue\n",
        "                yield s"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7yEgibtTRPQ"
      },
      "source": [
        "class RawSentenceReader:\n",
        "    def __init__(self, filepath):\n",
        "        self.filepath = filepath\n",
        "        self.rgxSplitter = re.compile('([.!?:](?:[\"\\']|(?![0-9])))')\n",
        " \n",
        "    def __iter__(self):\n",
        "        for line in open(self.filepath, encoding='utf-8'):\n",
        "            ch = self.rgxSplitter.split(line)\n",
        "            for s in map(lambda a, b: a + b, ch[::2], ch[1::2]):\n",
        "                if not s: continue\n",
        "                yield s"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrqZfXK4TRPR"
      },
      "source": [
        "#### 1. B. Komoran 형태소 분석기를 활용하여 단어의 품사를 태깅"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOFdTkiJTRPS"
      },
      "source": [
        "class RawTagger:\n",
        "    def __init__(self, textIter, tagger = None):\n",
        "        if tagger:\n",
        "            self.tagger = tagger\n",
        "        else :\n",
        "            from konlpy.tag import Komoran\n",
        "            self.tagger = Komoran()\n",
        "        if type(textIter) == str: self.textIter = textIter.split('\\n')\n",
        "        else: self.textIter = textIter\n",
        "        self.rgxSplitter = re.compile('([.!?:](?:[\"\\']|(?![0-9])))')\n",
        " \n",
        "    def __iter__(self):\n",
        "        for line in self.textIter:\n",
        "            ch = self.rgxSplitter.split(line)\n",
        "            for s in map(lambda a,b:a+b, ch[::2], ch[1::2]):\n",
        "                if not s: continue\n",
        "                yield self.tagger.pos(s)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZQMi9nbTRPT"
      },
      "source": [
        "class RawTaggerReader:\n",
        "    def __init__(self, filepath, tagger = None):\n",
        "        if tagger:\n",
        "            self.tagger = tagger\n",
        "        else :\n",
        "            from konlpy.tag import Komoran\n",
        "            self.tagger = Komoran()\n",
        "        self.filepath = filepath\n",
        "        self.rgxSplitter = re.compile('([.!?:](?:[\"\\']|(?![0-9])))')\n",
        " \n",
        "    def __iter__(self):\n",
        "        for line in open(self.filepath, encoding='utf-8'):\n",
        "            ch = self.rgxSplitter.split(line)\n",
        "            for s in map(lambda a,b:a+b, ch[::2], ch[1::2]):\n",
        "                if not s: continue\n",
        "                yield self.tagger.pos(s)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbXLXFHqTRPU"
      },
      "source": [
        "### 2. TextRank 클래스 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oZggg78TRPU"
      },
      "source": [
        "class TextRank:\n",
        "    def __init__(self, **kargs):\n",
        "        self.graph = None\n",
        "        self.window = kargs.get('window', 5)\n",
        "        self.coef = kargs.get('coef', 1.0)\n",
        "        self.threshold = kargs.get('threshold', 0.005)\n",
        "        self.dictCount = {}\n",
        "        self.dictBiCount = {}\n",
        "        self.dictNear = {}\n",
        "        self.nTotal = 0\n",
        "        \n",
        "    def load(self, sentenceIter, wordFilter = None):\n",
        "        def insertPair(a, b):\n",
        "            if a > b: a, b = b, a\n",
        "            elif a == b: return\n",
        "            self.dictBiCount[a, b] = self.dictBiCount.get((a, b), 0) + 1\n",
        " \n",
        "        def insertNearPair(a, b):\n",
        "            self.dictNear[a, b] = self.dictNear.get((a, b), 0) + 1\n",
        " \n",
        "        for sent in sentenceIter:\n",
        "            for i, word in enumerate(sent):\n",
        "                if wordFilter and not wordFilter(word): continue\n",
        "                self.dictCount[word] = self.dictCount.get(word, 0) + 1\n",
        "                self.nTotal += 1\n",
        "                if i - 1 >= 0 and (not wordFilter or wordFilter(sent[i-1])): insertNearPair(sent[i-1], word)\n",
        "                if i + 1 < len(sent) and (not wordFilter or wordFilter(sent[i+1])): insertNearPair(word, sent[i+1])\n",
        "                for j in range(i+1, min(i+self.window+1, len(sent))):\n",
        "                    if wordFilter and not wordFilter(sent[j]): continue\n",
        "                    if sent[j] != word: insertPair(word, sent[j])\n",
        " \n",
        "    def loadSents(self, sentenceIter, tokenizer = None):\n",
        "        import math\n",
        "        def similarity(a, b):\n",
        "            n = len(a.intersection(b))\n",
        "            return n / float(len(a) + len(b) - n) / (math.log(len(a)+1) * math.log(len(b)+1))\n",
        " \n",
        "        if not tokenizer: rgxSplitter = re.compile('[\\\\s.,:;-?!()\"\\']+')\n",
        "        sentSet = []\n",
        "        for sent in filter(None, sentenceIter):\n",
        "            if type(sent) == str:\n",
        "                if tokenizer: s = set(filter(None, tokenizer(sent)))\n",
        "                else: s = set(filter(None, rgxSplitter.split(sent)))\n",
        "            else: s = set(sent)\n",
        "            if len(s) < 2: continue\n",
        "            self.dictCount[len(self.dictCount)] = sent\n",
        "            sentSet.append(s)\n",
        " \n",
        "        for i in range(len(self.dictCount)):\n",
        "            for j in range(i+1, len(self.dictCount)):\n",
        "                s = similarity(sentSet[i], sentSet[j])\n",
        "                if s < self.threshold: continue\n",
        "                self.dictBiCount[i, j] = s\n",
        " \n",
        "    def getPMI(self, a, b):\n",
        "        import math\n",
        "        co = self.dictNear.get((a, b), 0)\n",
        "        if not co: return None\n",
        "        return math.log(float(co) * self.nTotal / self.dictCount[a] / self.dictCount[b])\n",
        " \n",
        "    def getI(self, a):\n",
        "        import math\n",
        "        if a not in self.dictCount: return None\n",
        "        return math.log(self.nTotal / self.dictCount[a])\n",
        " \n",
        "    def build(self):\n",
        "        self.graph = networkx.Graph()\n",
        "        self.graph.add_nodes_from(self.dictCount.keys())\n",
        "        for (a, b), n in self.dictBiCount.items():\n",
        "            self.graph.add_edge(a, b, weight=n*self.coef + (1-self.coef))\n",
        " \n",
        "    def rank(self):\n",
        "        return networkx.pagerank(self.graph, weight='weight')\n",
        " \n",
        "    def extract(self, ratio = 0.1):\n",
        "        ranks = self.rank()\n",
        "        cand = sorted(ranks, key=ranks.get, reverse=True)[:int(len(ranks) * ratio)]\n",
        "        pairness = {}\n",
        "        startOf = {}\n",
        "        tuples = {}\n",
        "        for k in cand:\n",
        "            tuples[(k,)] = self.getI(k) * ranks[k]\n",
        "            for l in cand:\n",
        "                if k == l: continue\n",
        "                pmi = self.getPMI(k, l)\n",
        "                if pmi: pairness[k, l] = pmi\n",
        " \n",
        "        for (k, l) in sorted(pairness, key=pairness.get, reverse=True):\n",
        "            print(k[0], l[0], pairness[k, l])\n",
        "            if k not in startOf: startOf[k] = (k, l)\n",
        " \n",
        "        for (k, l), v in pairness.items():\n",
        "            pmis = v\n",
        "            rs = ranks[k] * ranks[l]\n",
        "            path = (k, l)\n",
        "            tuples[path] = pmis / (len(path) - 1) * rs ** (1 / len(path)) * len(path)\n",
        "            last = l\n",
        "            while last in startOf and len(path) < 7:\n",
        "                if last in path: break\n",
        "                pmis += pairness[startOf[last]]\n",
        "                last = startOf[last][1]\n",
        "                rs *= ranks[last]\n",
        "                path += (last,)\n",
        "                tuples[path] = pmis / (len(path) - 1) * rs ** (1 / len(path)) * len(path)\n",
        " \n",
        "        used = set()\n",
        "        both = {}\n",
        "        for k in sorted(tuples, key=tuples.get, reverse=True):\n",
        "            if used.intersection(set(k)): continue\n",
        "            both[k] = tuples[k]\n",
        "            for w in k: used.add(w)\n",
        " \n",
        "        #for k in cand:\n",
        "        #    if k not in used or True: both[k] = ranks[k] * self.getI(k)\n",
        " \n",
        "        return both\n",
        " \n",
        "    def summarize(self, ratio = 0.333):\n",
        "        r = self.rank()\n",
        "        ks = sorted(r, key=r.get, reverse=True)[:int(len(r)*ratio)]\n",
        "        return ' '.join(map(lambda k:self.dictCount[k], sorted(ks)))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zl9uUtoeTRPY"
      },
      "source": [
        "### 3. TextRank 알고리즘을 활용하여 문서를 요약하는 함수 정의\n",
        "\n",
        "- (참고) 요약 비율은 문서의 20%\n",
        "- (참고) \"휴면\"이 포함된 문장은 모두 추출"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7p-F2HZ1Wi_F"
      },
      "source": [
        ""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcThWw8OTRPZ"
      },
      "source": [
        "def summarise_contents(x):\n",
        "    tr = TextRank()\n",
        "\n",
        "    stopword = set([('있', 'VV'), ('하', 'VV'), ('되', 'VV') ])\n",
        "    \n",
        "  \n",
        "    #tr.loadSents(RawSentence(x), lambda sent: filter(lambda y:y not in stopword and y[1] in ('NNG', 'NNP', 'VV', 'VA','ab'), tagger.pos(sent)))\n",
        "    tr.loadSents(RawSentence(x), lambda sent: filter(lambda y:y not in stopword and y[1] in ('NNG', 'NNP', 'VV', 'VA'), tagger.pos(sent)))\n",
        "    tr.build()\n",
        "    ranks = tr.rank()\n",
        "    return tr.summarize(0.2)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qC6hl41TRPa"
      },
      "source": [
        "def extract_resting(x): #여기서 꼭 들어가야 되는 단어 정하기\n",
        "    \n",
        "    out = ''\n",
        "    for line in x.split('\\n'):\n",
        "        if not line.isspace() and '휴면' in line:\n",
        "            out += line + ' '\n",
        "    return out.strip()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CJrF5SNjQ6K"
      },
      "source": [
        "def extract_resting2(x): #여기서 들어가면 안되는 단어 정하기\n",
        "    \n",
        "    out = ''\n",
        "    for line in x.split('\\n'):\n",
        "        if not line.isspace() and '준수합니다' not in line and '노력합니다' not in line:\n",
        "            out += line + ' '\n",
        "    return out.strip()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrXnY6f_TRPa"
      },
      "source": [
        "### 4. Data load"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLU5PS6MTRPb"
      },
      "source": [
        "#### 4. A. Data load _ Colab ver."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTTXwzNLTRPb"
      },
      "source": [
        "#### Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-jBAJgwTRPc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aed43996-6525-45e1-f602-b8e54fe159d2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yb6W4vZlTRPc"
      },
      "source": [
        "file_list = glob.glob('./drive/MyDrive/data/*_raw.txt')\n",
        "regex_idx = re.compile('[0-9]+')\n",
        "regex_text = re.compile('[^0-9a-zA-Z가-힣.()\\n]+')\n",
        "dict_ = {}\n",
        "\n",
        "for file in file_list:\n",
        "    sentence = ''\n",
        "    idx = re.findall(regex_idx, file)[0]\n",
        "    with open(file, 'r') as f:\n",
        "        for line in f.readlines():\n",
        "            sentence += line\n",
        "    dict_[int(idx)] = re.sub(regex_text, ' ', sentence)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lx9hgo5tTRPd"
      },
      "source": [
        "#### 4. B. Data load _ Local ver."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kD82V7JzTRPd"
      },
      "source": [
        "#### Local"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lh_esThMTRPe"
      },
      "source": [
        "#file_list = glob.glob('../data/*_raw.txt')\n",
        "#regex_idx = re.compile('[0-9]+')\n",
        "#regex_text = re.compile('[^0-9a-zA-Z가-힣.()\\n]+')\n",
        "#dict_ = {}\n",
        "\n",
        "#for file in file_list:\n",
        " #   sentence = ''\n",
        "  #  idx = re.findall(regex_idx, file)[0]\n",
        "   # with open(file, 'r') as f:\n",
        "    #     for line in f.readlines():\n",
        "     #        sentence += line\n",
        "    #dict_[int(idx)] = re.sub(regex_text, ' ', sentence)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1xRT48JV6La"
      },
      "source": [
        "#glob.glob('../data/*_raw.txt')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZuqEDppWbrT"
      },
      "source": [
        ""
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Cl6tGYrTRPe"
      },
      "source": [
        "data = pd.DataFrame.from_dict(dict_, orient='index', columns=['Text'])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnajZAanTRPf"
      },
      "source": [
        "### 5. 문서요약 실행"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RC-gB1i3TRPf",
        "outputId": "656dba01-c4ae-4a06-999f-89a046a8990b"
      },
      "source": [
        "data['Text2'] = data['Text'].map(lambda x : extract_resting2(x))\n",
        "data['Text_Rank'] = data['Text2'].map(lambda x: (summarise_contents(x)) if len(x) >1000 else \"The sentence is too short to summarize..\" )\n",
        "data['Resting'] = data['Text'].map(lambda x :  extract_resting(x))\n",
        "data['Summary'] = data['Text_Rank'] +'---------------------------------------------------------------------------'+data['Resting']\n",
        "#data['Summary'] = data['Resting2']\n",
        "\n",
        "# df.to_csv('sample.csv', index = False) # 결과를 저장\n",
        "print(\"Done ! \")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done ! \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "Fpl4EJsSTRPg",
        "outputId": "5648857f-4b1a-4c0b-fed9-33158874074a"
      },
      "source": [
        "data['Text'][1] # Dataframe의 index는 sample 번호와 일치 ,원문"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' 서비스 이용약관 \\n\\n제1조 목적\\n본 약관(이하 약관 )은 웰(이하 회사)와 회원에 관한 제반사항을 규정함을 목적으로 합니다.\\n\\n제2조 용어의 정의\\n 회원 은 회사에 개인정보를 제공하여 회원등록을 한 자로서 회사가 제공하는 서비스를 계속적으로 이용할 수 있는 자를 말합니다.\\n\\n제3조 약관의 게시 및 변경\\n 회사는 약관의 규제에 관한 법률 전자거래기본법 정보통신망이용촉진등에관한법률 소비자보호법 등 관련법을 위배하지 않는 범위에서 이 약관을 개정할 수 있습니다.\\n\\n제4조 약관 외 준칙 및 관할법원\\n 본 약관에 명시되지 않은 사항은 국내 관계법에 준하여 해석합니다.\\n 회원과 회사 사이에 분쟁이 발생할 경우 서울민사지방법원을 관할 법원으로 합니다.\\n\\n제5조 회원가입 및 자격\\n 회사가 정한 양식에 따라 회원정보를 기입한 후 회원가입을 신청함으로써 회원으로 등록됩니다.\\n 다음 각 호의 1에 해당하는 경우 회사가 임의적으로 회원가입을 인정하지 않거나 회원자격을 박탈할 수 있습니다.\\n1. 다른 사람의 명의를 사용하여 신청하였을 경우\\n2. 신청 시 필수 내용을 허위로 기재하여 신청하였을 경우\\n\\n제6조 개인정보의 취득 및 이용\\n 회사는 고객의 개인정보의 취득과 이용 보호 등에 관한 사항을 개인정보보호정책 에 정한 바에 따르며 개인정보보호정책은 홈페이지 하단에 상시적으로 게시합니다.\\n 회사는 고객으로부터 각종 개인신상에 관한 정보를 제공받을 수 있으며 제공받은 정보는 회사가 제공하는 서비스를 고객이 효율적으로 이용할 수 있도록 하는데 사용될 수 있습니다.\\n\\n제7조 휴면아이디 관리\\n 회원이 2년 이상 로그인 및 서비스 이용 기록이 없는 경우 해당 회원의 아이디는 휴면아이디가 되어 회원 로그인이 정지되고 회사는 휴면아이디의 회원정보를 다른 아이디와 별도로 1년 동안 관리합니다.\\n 회사는 1항에 의한 회원 로그인 이용정지 10일 전 이메일을 통하여 이용정지에 대하여 안내하고 이용정지가 되는 경우 다시 이메일을 통하여 이용정지 사실에 대하여 고지합니다.\\n 회원은 회원 로그인 이용정지 이후에 사이트 상에서 아이디와 비밀번호를 입력하고 로그인을 하면 휴면상태 해지신청이 되어 즉시 다시 정상적으로 서비스를 이용할 수 있습니다.\\n 회원이 휴면아이디가 된 후 1년 이내에 휴면상태 해지신청을 하지 않은 경우 해당 회원의 회원정보를 삭제합니다.\\n 회사는 4항에 의한 회원정보 삭제 10일 전 이메일을 통하여 회원정보 삭제에 대하여 안내하고 회원정보 삭제가 되는 경우 다시 이메일을 통하여 고지합니다.\\n\\n제8조 회원 탈퇴\\n 회원은 회사에 언제든지 탈퇴를 요청할 수 있으며 지체없이 회원탈퇴를 처리합니다.\\n 회원이 회사의 유료 서비스를 이용할 경우 이용중인 서비스가 해지완료 되지 않았거나 도메인 서비스 만기일이 지나지 않은 경우에는 본 약관 제8조에 따라 고객에게 해당 내용을 통지후 탈퇴 처리 하지 않습니다.\\n\\n제9조 회원에 대한 통지\\n 회사가 회원에 대한 통지를 하는 경우 회원이 회사에 제출한 전자우편주소로 할 수 있습니다.\\n 회사는 불특정다수 회원에 대한 통지의 경우 1주일이상 회사 게시판에 게시함으로서 개별 통지에 갈음할 수 있습니다.\\n제10조 회사의 의무\\n 회사는 본 약관이 정하는 바에 따라 지속적이고 안정적인 서비스를 제공하는데 최선을 다하여야 합니다.\\n 회사는 항상 등록자의 정보를 포함한 개인신상정보에 대하여 관리적 기술적 안전조치를 강구하여 정보보안에 최선을 다하여야 합니다.\\n 회사는 공정하고 건전한 운영을 통하여 전자상거래 질서유지에 최선을 다하고 지속적인 연구개발을 통하여 양질의 서비스를 제공함으로써 고객만족을 극대화하여 인터넷 사업 발전에 기여합니다.\\n 회사는 고객으로부터 제기되는 불편사항 및 문제에 대해 정당하다고 판단될 경우 우선적으로 그 문제를 지체없이 처리해야 합니다. 단 신속한 처리가 곤란할 경우 고객에게 그 사유와 처리일정을 통지하여야 합니다.\\n 회사는 소비자 보호단체 및 공공기관의 소비자 보호업무의 추진에 필요한 자료 등의 요구에 적극 협력합니다.\\n\\n제11조 회원의 의무\\n ID와 비밀번호에 관한 모든 관리의 책임은 회원에게 있습니다.\\n 회원은 ID와 비밀번호를 제3자가 알 수 있도록 해서는 안됩니다.\\n 회원은 본 약관 및 관계법령에서 규정한 사항을 준수해야 합니다.\\n 다음 각 호의 1에 해당하는 행위를 할 경우 이용권리가 박탈됩니다.\\n1. 범죄와 결부된다고 객관적으로 판단되는 행위\\n2. 기타 관계법령에 위배되는 행위'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "LGyv9vRCMo88",
        "outputId": "c658bc18-da8f-4891-e0ac-35517ae43960"
      },
      "source": [
        "data['Text2'][1] #원문에서 stopword가 들어간 문장 전체를 제거한 것"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'서비스 이용약관   제1조 목적 본 약관(이하 약관 )은 웰(이하 회사)와 회원에 관한 제반사항을 규정함을 목적으로 합니다.  제2조 용어의 정의  회원 은 회사에 개인정보를 제공하여 회원등록을 한 자로서 회사가 제공하는 서비스를 계속적으로 이용할 수 있는 자를 말합니다.  제3조 약관의 게시 및 변경  회사는 약관의 규제에 관한 법률 전자거래기본법 정보통신망이용촉진등에관한법률 소비자보호법 등 관련법을 위배하지 않는 범위에서 이 약관을 개정할 수 있습니다.  제4조 약관 외 준칙 및 관할법원  본 약관에 명시되지 않은 사항은 국내 관계법에 준하여 해석합니다.  회원과 회사 사이에 분쟁이 발생할 경우 서울민사지방법원을 관할 법원으로 합니다.  제5조 회원가입 및 자격  회사가 정한 양식에 따라 회원정보를 기입한 후 회원가입을 신청함으로써 회원으로 등록됩니다.  다음 각 호의 1에 해당하는 경우 회사가 임의적으로 회원가입을 인정하지 않거나 회원자격을 박탈할 수 있습니다. 1. 다른 사람의 명의를 사용하여 신청하였을 경우 2. 신청 시 필수 내용을 허위로 기재하여 신청하였을 경우  제6조 개인정보의 취득 및 이용  회사는 고객의 개인정보의 취득과 이용 보호 등에 관한 사항을 개인정보보호정책 에 정한 바에 따르며 개인정보보호정책은 홈페이지 하단에 상시적으로 게시합니다.  회사는 고객으로부터 각종 개인신상에 관한 정보를 제공받을 수 있으며 제공받은 정보는 회사가 제공하는 서비스를 고객이 효율적으로 이용할 수 있도록 하는데 사용될 수 있습니다.  제7조 휴면아이디 관리  회원이 2년 이상 로그인 및 서비스 이용 기록이 없는 경우 해당 회원의 아이디는 휴면아이디가 되어 회원 로그인이 정지되고 회사는 휴면아이디의 회원정보를 다른 아이디와 별도로 1년 동안 관리합니다.  회사는 1항에 의한 회원 로그인 이용정지 10일 전 이메일을 통하여 이용정지에 대하여 안내하고 이용정지가 되는 경우 다시 이메일을 통하여 이용정지 사실에 대하여 고지합니다.  회원은 회원 로그인 이용정지 이후에 사이트 상에서 아이디와 비밀번호를 입력하고 로그인을 하면 휴면상태 해지신청이 되어 즉시 다시 정상적으로 서비스를 이용할 수 있습니다.  회원이 휴면아이디가 된 후 1년 이내에 휴면상태 해지신청을 하지 않은 경우 해당 회원의 회원정보를 삭제합니다.  회사는 4항에 의한 회원정보 삭제 10일 전 이메일을 통하여 회원정보 삭제에 대하여 안내하고 회원정보 삭제가 되는 경우 다시 이메일을 통하여 고지합니다.  제8조 회원 탈퇴  회원은 회사에 언제든지 탈퇴를 요청할 수 있으며 지체없이 회원탈퇴를 처리합니다.  회원이 회사의 유료 서비스를 이용할 경우 이용중인 서비스가 해지완료 되지 않았거나 도메인 서비스 만기일이 지나지 않은 경우에는 본 약관 제8조에 따라 고객에게 해당 내용을 통지후 탈퇴 처리 하지 않습니다.  제9조 회원에 대한 통지  회사가 회원에 대한 통지를 하는 경우 회원이 회사에 제출한 전자우편주소로 할 수 있습니다.  회사는 불특정다수 회원에 대한 통지의 경우 1주일이상 회사 게시판에 게시함으로서 개별 통지에 갈음할 수 있습니다. 제10조 회사의 의무  회사는 본 약관이 정하는 바에 따라 지속적이고 안정적인 서비스를 제공하는데 최선을 다하여야 합니다.  회사는 항상 등록자의 정보를 포함한 개인신상정보에 대하여 관리적 기술적 안전조치를 강구하여 정보보안에 최선을 다하여야 합니다.  회사는 공정하고 건전한 운영을 통하여 전자상거래 질서유지에 최선을 다하고 지속적인 연구개발을 통하여 양질의 서비스를 제공함으로써 고객만족을 극대화하여 인터넷 사업 발전에 기여합니다.  회사는 고객으로부터 제기되는 불편사항 및 문제에 대해 정당하다고 판단될 경우 우선적으로 그 문제를 지체없이 처리해야 합니다. 단 신속한 처리가 곤란할 경우 고객에게 그 사유와 처리일정을 통지하여야 합니다.  회사는 소비자 보호단체 및 공공기관의 소비자 보호업무의 추진에 필요한 자료 등의 요구에 적극 협력합니다.  제11조 회원의 의무  ID와 비밀번호에 관한 모든 관리의 책임은 회원에게 있습니다.  회원은 ID와 비밀번호를 제3자가 알 수 있도록 해서는 안됩니다.  회원은 본 약관 및 관계법령에서 규정한 사항을 준수해야 합니다.  다음 각 호의 1에 해당하는 행위를 할 경우 이용권리가 박탈됩니다. 1. 범죄와 결부된다고 객관적으로 판단되는 행위 2. 기타 관계법령에 위배되는 행위'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZ25kX3ITRPg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "b928b295-5b43-4a0b-a1a2-99eac21fd948"
      },
      "source": [
        "data['Summary'][1]#요약문 "
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'서비스 이용약관   제1조 목적 본 약관(이하 약관 )은 웰(이하 회사)와 회원에 관한 제반사항을 규정함을 목적으로 합니다.   회원과 회사 사이에 분쟁이 발생할 경우 서울민사지방법원을 관할 법원으로 합니다.   다음 각 호의 1에 해당하는 경우 회사가 임의적으로 회원가입을 인정하지 않거나 회원자격을 박탈할 수 있습니다.   회사는 1항에 의한 회원 로그인 이용정지 10일 전 이메일을 통하여 이용정지에 대하여 안내하고 이용정지가 되는 경우 다시 이메일을 통하여 이용정지 사실에 대하여 고지합니다.   제8조 회원 탈퇴  회원은 회사에 언제든지 탈퇴를 요청할 수 있으며 지체없이 회원탈퇴를 처리합니다.   제9조 회원에 대한 통지  회사가 회원에 대한 통지를 하는 경우 회원이 회사에 제출한 전자우편주소로 할 수 있습니다.---------------------------------------------------------------------------제7조 휴면아이디 관리  회원이 2년 이상 로그인 및 서비스 이용 기록이 없는 경우 해당 회원의 아이디는 휴면아이디가 되어 회원 로그인이 정지되고 회사는 휴면아이디의 회원정보를 다른 아이디와 별도로 1년 동안 관리합니다.  회원은 회원 로그인 이용정지 이후에 사이트 상에서 아이디와 비밀번호를 입력하고 로그인을 하면 휴면상태 해지신청이 되어 즉시 다시 정상적으로 서비스를 이용할 수 있습니다.  회원이 휴면아이디가 된 후 1년 이내에 휴면상태 해지신청을 하지 않은 경우 해당 회원의 회원정보를 삭제합니다.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jxeo-QLcdNCn"
      },
      "source": [
        "#a=data['Summary'][1]# 만약 data['Summary'][1]값이 출력 안될때 "
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AH1kIE_BhUHS"
      },
      "source": [
        "#print(a)"
      ],
      "execution_count": 21,
      "outputs": []
    }
  ]
}